
---

# ğŸ“Š Competitor Monitor

> **Intelligent web application for competitive monitoring with AI analysis**

A comprehensive solution to automatically monitor competitor e-commerce websites, detect price changes and new products using artificial intelligence.
<img src="docs/screenshots/landing_page.png" style="height:256px;margin-right:256px"/>

---

## ğŸ“‘ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Architecture](#-architecture)
- [Technologies](#-technologies)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Usage](#-usage)
- [Project Structure](#-project-structure)
- [Testing](#-testing)
- [Screenshots](#-screenshots)


---

## ğŸ¯ Overview

**Competitor Monitor** is a Django web application designed to help businesses monitor their online competitors. The system uses intelligent web scraping coupled with a local Large Language Model (LLM) to automatically extract and analyze product data.

### Use Cases

- ğŸª **E-commerce** : Monitor competitor prices
- ğŸ“ˆ **Strategic Intelligence** : Detect new product launches
- ğŸ’° **Pricing Optimization** : Receive alerts on price changes
- ğŸ¯ **Business Intelligence** : Analyze market trends

---

## âœ¨ Features

### For Clients

- **ğŸ” Competitor Monitoring**
  - Unlimited addition of competitor websites to track
  - Manual scraping triggered on-demand
  - Overview of all competitors with statistics
- **ğŸ“¦ Product Management**
  - Automatic catalog of scraped products
  - Display with images, descriptions and categories
  - Complete price history with interactive charts
- **ğŸ”” Alert System**
  - Real-time notifications for price changes (Â±5% minimum)
  - Alerts for newly detected products
  - Filtering by type (price increase/decrease, new products)
  - Unread alerts badge in navigation
- **ğŸ“Š Data Visualization**
  - Price charts with Chart.js
  - Trends over last 30 history entries
  - Interactive statistics cards

### For Administrators

- **ğŸ‘¥ Client Management (CRUD)**
  - Create, edit, delete accounts
  - Account activation/deactivation
  - Advanced search and filtering
- **ğŸ“ˆ Global Statistics**
  - Platform overview
  - Most active clients
  - Recently registered clients
  - Per-client metrics
- **ğŸ” Detailed Analysis**
  - Per-client statistics (competitors, products, alerts)
  - Per-competitor details for each client

### Technical Features

- **ğŸ¤– AI Extraction with Ollama**
  - Local Llama 3.1 usage (no API costs)
  - Structured extraction with Pydantic validation
  - Optimized prompts for e-commerce extraction
- **ğŸŒ Intelligent Scraping**
  - Selenium for JavaScript-heavy websites
  - BeautifulSoup for DOM cleaning
  - Error handling and automatic retry
- **ğŸ’¾ Optimized Database**
  - PostgreSQL with indexes for performance
  - Unlimited price history
  - Uniqueness constraints to avoid duplicates

---

## ğŸ—ï¸ database_schema

<img src="docs/screenshots/database_schema.png" style="height:256px;margin-right:256px"/>

### Scraping Pipeline

```
1. Selenium â†’ HTML Retrieval (with JS)
2. BeautifulSoup â†’ DOM Cleaning
3. Text Splitting â†’ 7500 char batches
4. Ollama LLM â†’ Structured JSON extraction
5. Pydantic â†’ Data validation
6. PostgreSQL â†’ Storage + History
7. Analysis â†’ Price comparison â†’ Alerts
```

---

## ğŸ› ï¸ Technologies

### Backend

- **Django 5.0** - Web framework
- **Django Rest Framework** - REST API
- **PostgreSQL 15+** - Database
- **Pydantic 2.10** - Data validation

### Scraping \& AI

- **Selenium 4.18** - Browser automation
- **BeautifulSoup 4.12** - HTML parsing
- **Ollama** - Local LLM (Llama 3.1)
- **webdriver-manager** - ChromeDriver management

### Frontend

- **Bootstrap 5.3** - CSS framework
- **Chart.js 4.4** - Interactive charts
- **FontAwesome 6.4** - Icons

### Utilities

- **python-decouple** - Environment variables
- **psycopg2-binary** - PostgreSQL connector

---

## ğŸ“¥ Installation

### Prerequisites

- **Python 3.10+**
- **PostgreSQL 15+**
- **Ollama** (for local LLM)
- **Google Chrome** (for Selenium)

### Step 1: Clone the Project

```bash
git clone https://github.com/wahib-bachoua/competitor-monitor.git
cd competitor-monitor
```

### Step 2: Create Virtual Environment

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 4: Install Ollama and LLM Model

```bash
# Install Ollama (https://ollama.ai)
# Linux/Mac
curl -fsSL https://ollama.com/install.sh | sh

# Windows: Download from https://ollama.com/download

# Download Llama 3.1 model
ollama pull llama3.1

# Verify installation
ollama list
```

### Step 5: Configure PostgreSQL

```bash
# Connect to PostgreSQL
psql -U postgres

# Create database
CREATE DATABASE competitor_monitor_db;

# Create user (optional)
CREATE USER competitor_user WITH PASSWORD 'your_password';
GRANT ALL PRIVILEGES ON DATABASE competitor_monitor_db TO competitor_user;

\q
```

---

## âš™ï¸ Configuration

### `.env` File

Create a `.env` file at project root:

```env
# Database
DB_NAME=competitor_monitor_db
DB_USER=postgres
DB_PASSWORD=your_password
DB_HOST=localhost
DB_PORT=5432

# Django
DEBUG=True
SECRET_KEY=your-very-long-random-django-secret-key

# Optional
ALLOWED_HOSTS=localhost,127.0.0.1
```

### Generate SECRET_KEY

```bash
python -c "from django.core.management.utils import get_random_secret_key; print(get_random_secret_key())"
```

### Migrations

```bash
# Create migrations
python manage.py makemigrations

# Apply migrations
python manage.py migrate
```

### Create Superuser

```bash
python manage.py createsuperuser
```

Follow the prompts to create your admin account.

---

## ğŸš€ Usage

### Start the Server

```bash
# Launch Ollama (in separate terminal)
ollama serve

# Launch Django
python manage.py runserver
```

Access the application: **http://127.0.0.1:8000**

### Client Workflow

1. **Sign Up/Login**
   - Create a client account or log in
2. **Add a Competitor**
   - Click "Add competitor"
   - Enter name and website URL (e.g., https://www.example-shop.com)
3. **Launch Scraping**
   - Click the green ğŸ”½ (Download) button on competitor row
   - Wait for scraping to complete (may take 1-3 minutes)
4. **View Products**
   - Click the blue badge showing product count
   - Explore detected products with images and prices
5. **Analyze Prices**
   - After a 2nd scraping, click the yellow ğŸ“Š (Analyze) button
   - Check generated alerts in "Alerts" section
6. **Check History**
   - Click "View history" on a product
   - Visualize price chart over time

### Administrator Workflow

1. **Admin Login**
   - Log in with your superuser account
   - Access Admin Dashboard
2. **Manage Clients**
   - View list of all clients
   - Create, edit, delete accounts
   - Activate/deactivate accounts
3. **View Statistics**
   - Global platform overview
   - Per-client statistics
   - Most active clients

---

## ğŸ“ Project Structure

```
competitor-monitor/
â”‚
â”œâ”€â”€ auth_app/                      # Authentication application
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â”œâ”€â”€ base_auth.html        # Template for auth pages
â”‚   â”‚   â”œâ”€â”€ base_app.html         # Template for application
â”‚   â”‚   â”œâ”€â”€ connexion.html
â”‚   â”‚   â”œâ”€â”€ inscription.html
â”‚   â”‚   â”œâ”€â”€ client_dashboard.html
â”‚   â”‚   â”œâ”€â”€ admin_dashboard.html
â”‚   â”‚   â””â”€â”€ admin/
â”‚   â”‚       â”œâ”€â”€ client_list.html
â”‚   â”‚       â”œâ”€â”€ client_form.html
â”‚   â”‚       â”œâ”€â”€ client_stats.html
â”‚   â”‚       â””â”€â”€ client_delete_confirm.html
â”‚   â”œâ”€â”€ forms.py                  # Auth + admin forms
â”‚   â”œâ”€â”€ views.py                  # Auth + CRUD client views
â”‚   â”œâ”€â”€ urls.py
â”‚   â””â”€â”€ context_processors.py     # Navbar alert counter
â”‚
â”œâ”€â”€ competitors/                   # Main application
â”‚   â”œâ”€â”€ templates/competitors/
â”‚   â”‚   â”œâ”€â”€ competitor_list.html
â”‚   â”‚   â”œâ”€â”€ competitor_form.html
â”‚   â”‚   â”œâ”€â”€ competitor_delete_confirm.html
â”‚   â”‚   â”œâ”€â”€ product_list.html
â”‚   â”‚   â””â”€â”€ product_detail.html
â”‚   â”œâ”€â”€ management/commands/
â”‚   â”‚   â””â”€â”€ test_price_change.py  # Test command
â”‚   â”œâ”€â”€ models.py                 # Competitor, Product, PriceHistory, ScrapeSession
â”‚   â”œâ”€â”€ views.py                  # CRUD + scraping triggers
â”‚   â”œâ”€â”€ forms.py                  # CompetitorForm
â”‚   â”œâ”€â”€ scraper.py                # Production scraping pipeline
â”‚   â”œâ”€â”€ scraper_test.py           # Test scraping pipeline
â”‚   â”œâ”€â”€ save_html_for_test.py     # Test utility
â”‚   â””â”€â”€ admin.py
â”‚
â”œâ”€â”€ alerts/                        # Alerts application
â”‚   â”œâ”€â”€ templates/alerts/
â”‚   â”‚   â””â”€â”€ alert_list.html
â”‚   â”œâ”€â”€ models.py                 # Alert
â”‚   â”œâ”€â”€ views.py                  # List + alert actions
â”‚   â””â”€â”€ urls.py
â”‚
â”œâ”€â”€ utils/                         # Reusable utilities
â”‚   â”œâ”€â”€ dom_cleaner.py            # HTML cleaning
â”‚   â””â”€â”€ llm_processor.py          # Ollama LLM interface
â”‚
â”œâ”€â”€ competitor_monitor/            # Django configuration
â”‚   â”œâ”€â”€ settings.py
â”‚   â”œâ”€â”€ urls.py
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.css
â”‚   â”‚   â”‚   â””â”€â”€ app.css
â”‚   â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”‚   â””â”€â”€ login-bg.jpg
â”‚   â”‚   â””â”€â”€ favicon.ico
â”‚   â””â”€â”€ wsgi.py
â”‚
â”œâ”€â”€ test_data/                     # Test data (optional)
â”‚   â”œâ”€â”€ original_scrape.html
â”‚   â””â”€â”€ modified_scrape.html
â”‚
â”œâ”€â”€ manage.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                          # Environment variables
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ§ª Testing

### Manual Scraping Test

```bash
python manage.py shell
```

```python
from competitors.scraper import scrape_competitor_website

# Replace with your competitor UUID
result = scrape_competitor_website('competitor-uuid')
print(result)
```

### Price Change Test

```bash
# 1. Save HTML from a scraping session
python manage.py shell
>>> from competitors.save_html_for_test import save_latest_scrape_html
>>> save_latest_scrape_html('competitor-uuid')

# 2. Manually modify test_data/modified_scrape.html

# 3. Run the test
python manage.py test_price_change competitor-uuid
```

### Unit Tests (coming soon)

```bash
python manage.py test
```

---

## ğŸ“¸ Screenshots

<table width="100%">
  <tr>
    <td align="center" width="50%">
      <h3>Login Page</h3>
      <img src="docs/screenshots/login.png" alt="Login Page" style="width: 100%; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.15); border: 1px solid #e0e0e0;"/>
    </td>
    <td align="center" width="50%">
      <h3>Client Dashboard</h3>
      <img src="docs/screenshots/dashboard_client.png" alt="Client Dashboard" style="width: 100%; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.15); border: 1px solid #e0e0e0;"/>
    </td>
  </tr>
  <tr>
    <td align="center" width="50%">
      <h3>Competitor List</h3>
      <img src="docs/screenshots/competitor_list.png" alt="Competitor List" style="width: 100%; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.15); border: 1px solid #e0e0e0;"/>
    </td>
    <td align="center" width="50%">
      <h3>Product Detail</h3>
      <img src="docs/screenshots/product_detail.png" alt="Product Detail" style="width: 100%; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.15); border: 1px solid #e0e0e0;"/>
    </td>
  </tr>
  <tr>
    <td align="center" width="50%">
      <h3>Alerts List</h3>
      <img src="docs/screenshots/alerts.png" alt="Alerts" style="width: 100%; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.15); border: 1px solid #e0e0e0;"/>
    </td>
    <td align="center" width="50%">
      <h3>Admin Dashboard</h3>
      <img src="docs/screenshots/dashboard_admin.png" alt="Admin Dashboard" style="width: 100%; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.15); border: 1px solid #e0e0e0;"/>
    </td>
  </tr>
</table>

---

## ğŸ“ Academic Context

This project was developed as part of an **academic project** to demonstrate:

- AI (LLM) integration in web applications
- Ethical web scraping techniques
- MVC architecture with Django
- Relational database management
- Modern UX/UI design with Bootstrap

**Intentional Limitations:**

- No automatic scheduled scraping (Celery not used)
- Manual scraping triggered by user
- Focus on simplicity and maintainability

---

## ğŸ”’ Legal Considerations

### Ethical Web Scraping

âš ï¸ **Important**: This project is designed for educational purposes. When using in production:

- Respect websites' `robots.txt` files
- Don't overload servers (delays between requests)
- Check Terms of Service of websites
- Use identifiable user-agents
- Only scrape public data

### GDPR Compliance

If collecting personal data:

- Inform users (privacy policy)
- Obtain consent
- Allow data access/deletion
- Secure stored data

---

## ğŸ—ºï¸ Future Roadmap

- Automatic scraping with Celery Beat
- Data export (CSV, Excel)
- Email notifications
- Public REST API
- Mobile application (React Native)
- Multi-currency support
- Multi-competitor comparison
- Generated PDF reports
- Slack/Discord integration for alerts
- Multi-tenant mode

---

<div align="center">

**â­ If this project was helpful, please give it a star! â­**

Made with â¤ï¸ by [wahib]

</div>

---
